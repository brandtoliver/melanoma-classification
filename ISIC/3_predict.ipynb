{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "import os\n",
    "os.chdir(\"/home/ubuntu/data/\")\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Image, display, clear_output\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/applications/vgg16.py:182: UserWarning: You are using the TensorFlow backend, yet you are using the Theano image data format convention (`image_data_format=\"channels_first\"`). For best performance, set `image_data_format=\"channels_last\"` in your Keras config at ~/.keras/keras.json.\n",
      "  warnings.warn('You are using the TensorFlow backend, yet you '\n"
     ]
    }
   ],
   "source": [
    "# path to the model weights files.\n",
    "weights_path = '../vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'validation'\n",
    "test_dir = 'test'\n",
    "nb_train_samples = 800\n",
    "nb_validation_samples = 370\n",
    "epochs = 2\n",
    "batch_size = 5\n",
    "\n",
    "input_tensor = Input(shape=(3,img_width,img_height))\n",
    "base_model = applications.VGG16(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "#top_model.load_weights(top_model_weights_path)\n",
    "model = Model(inputs= base_model.input, outputs= top_model(base_model.output))\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.load_weights('last_and_finetuned_15fixed.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "files_benign=os.listdir(test_dir+\"/Benign/\")\n",
    "files_malignant=os.listdir(test_dir+\"/Malignant/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test/Benign/ISIC_0010371.jpg\n",
      "(1, 3, 150, 150)\n",
      "[[ 0.64314294]]\n",
      "benign\n"
     ]
    }
   ],
   "source": [
    "def predict_image_class(file):\n",
    "    #load the VGG16 model\n",
    "    #model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "    #load the picture\n",
    "    x = image.load_img(file, target_size=(img_width,img_height))\n",
    "    x = image.img_to_array(x)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    print(x.shape)\n",
    "    # process the picture through the first network this will be used as input\n",
    "    #for the top model\n",
    "    #array = model.predict(x)\n",
    "    #build the top model\n",
    "    #model = Sequential()\n",
    "    #model.add(Flatten(input_shape=array.shape[1:]))\n",
    "    #model.add(Dense(256, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    #model.add(Dense(1, activation='sigmoid'))\n",
    "    # and use the weigths trained before\n",
    "    #model.load_weights(top_model_weights_path)\n",
    "    class_predicted = model.predict(x)\n",
    "    print(class_predicted)\n",
    "    if class_predicted==1:\n",
    "        print(\"malign\") # dog\n",
    "    else:\n",
    "        print(\"benign\") # cat\n",
    "        \n",
    "from keras.preprocessing import image\n",
    "\n",
    "print(test_dir + \"/Benign/\" + files_benign[0])\n",
    "predict_image_class(test_dir + \"/Benign/\" + files_benign[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 150, 150)\n",
      "[[ 0.]]\n",
      "benign\n"
     ]
    }
   ],
   "source": [
    "predict_image_class(\"validation/Benign/ISIC_0009874.jpg\")\n",
    "#\"IMG_0845c1.JPG\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
