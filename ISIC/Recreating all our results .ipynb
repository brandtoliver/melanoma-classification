{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to work on the server\n",
    "import os\n",
    "os.environ[\"CUDA DEVICE ORDER\"]=\"PCI BUS ID\"\n",
    "os.environ[\"CUDA VISIBLE DEVICES\"]=\"#gpunum\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "PATH='/home/jankoo/Project/data1/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook it is shown how we get our results. The main idea of our method is to do transfer-learning. We did download the weights corresponding to the VG16 model and then we first retrained the last layer to our first classes. Next we did finetune the last convolutional layers, taking care not do get overfitting by using a small learning rate.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this are the packages we used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path to the datafolder and the parameters. The data folder is divided in 3 subfolders test, train and validation, containing 20%, 60% and 20% of the data respectively. Each of  this folder is oneach turn split in two subfolders again, one malignant and wan benign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH=PATH#\"path to data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = PATH+'train/'\n",
    "validation_data_dir =PATH+ 'validation/'\n",
    "test_dir =PATH+ 'test/'\n",
    "nb_train_samples = 841\n",
    "nb_validation_samples = 373\n",
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the following data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we saved the bottleneck features, that is we took the VGG16 network. We took pathches of our data, aumentated it and loaded it through VG16 except the last layer. We did save the outcome of the network in in the bottle neck features. So we got bottleneck features for the train and validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_bottlebeck_features():\n",
    "    #datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "    np.save('bottleneck_features_train',\n",
    "        bottleneck_features_train)\n",
    "\n",
    "    print(\"done train\")\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    np.save('bottleneck_features_validation',\n",
    "            bottleneck_features_validation)\n",
    "    print(\"done valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used this bottleneck features as input of our top model. And we trained this top model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_top_model():\n",
    "    train_data = np.load('bottleneck_features_train.npy')\n",
    "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
    "\n",
    "    validation_data = np.load('bottleneck_features_validation.npy')\n",
    "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    print(\"starting fitting\")\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)\n",
    "    print(\"ended fitting and saving\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call our functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_bottlebeck_features()\n",
    "train_top_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that we are doing it correctly we have a function that can predict what we see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_image_class(file):\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "    x = load_img(file, target_size=(img_width,img_height))\n",
    "    x = img_to_array(x)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    array = model.predict(x)\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=array.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.load_weights(top_model_weights_path)\n",
    "    class_predicted = model.predict_classes(array)\n",
    "    if class_predicted==1:\n",
    "        print(\"malignant\")\n",
    "    else:\n",
    "        print(\"benign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nex we fine tune the last convolutional layers of VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to the model weights files.\n",
    "weights_path = '../vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'validation'\n",
    "test_dir = 'test'\n",
    "nb_train_samples = 800\n",
    "nb_validation_samples = 370\n",
    "epochs = 20\n",
    "batch_size = 5\n",
    "\n",
    "input_tensor = Input(shape=(3,img_width,img_height))\n",
    "base_model = applications.VGG16(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "model = Model(inputs= base_model.input, outputs= top_model(base_model.output))\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anylizing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is not such a good measure. Because of the nature of benign and malignant it is very important not to have too many false positives, i.e., too often diagnose malignant while it is benign. Therefore, we made the confucion matrix and the receiver operating characteristic and found an area under curve of 0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for trainValTest in [test_dir]:\n",
    "    \"\"\"\n",
    "    array:\n",
    "    0 actual class malignant\n",
    "    1 actual class benign\n",
    "    \"\"\"\n",
    "    confusion_matrix = [[0,0],[0,0]] \n",
    "    pred_array = [[],[]]\n",
    "    for a, category in enumerate(category_array):\n",
    "        cur_path = trainValTest + \"/\" + category + \"/\"\n",
    "        for file in progressbar.log_progress(os.listdir(cur_path)[:]):\n",
    "            if file.endswith(\".jpg\"):\n",
    "                path_file = cur_path + file\n",
    "                value_prediction = predict_image_class(model, path_file, img_width, img_height)\n",
    "                pred_array[a] += [value_prediction]\n",
    "                if value_prediction > 0.5:\n",
    "                    confusion_matrix[a][0] += 1\n",
    "                else:\n",
    "                    confusion_matrix[a][1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix[0])\n",
    "print(confusion_matrix[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TP = confusion_matrix[0][0]\n",
    "FP = confusion_matrix[0][1]\n",
    "FN = confusion_matrix[1][0]\n",
    "TN = confusion_matrix[1][1]\n",
    "\n",
    "AC = (TP+TN) / (TP+FP+TN+FN)#accuracy\n",
    "SE = TP / (TP+FN)#sensitivity\n",
    "SP = TN / (TN+FP)#specitifity\n",
    "DI = (2*TP) / (2*TP + FN + FP)#dice coefficient\n",
    "\n",
    "print(AC,SE,SP,DI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true_0 = np.ones(len(pred_array[0]))\n",
    "y_true_1 = np.zeros(len(pred_array[1]))\n",
    "y_true = np.concatenate([y_true_0, y_true_1],axis=0)\n",
    "y_score = np.concatenate(pred_array, axis=0)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
