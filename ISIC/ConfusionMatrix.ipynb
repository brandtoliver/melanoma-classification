{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img,array_to_img\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "import progressbar\n",
    "\n",
    "import os\n",
    "\n",
    "from IPython.display import Image, display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/home/dwx/Documents/Studium/DTU/11/DL Deep Learning/project/ISIC_MSK-2_1_sorted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_model(top_model_weights_path, img_width, img_height):\n",
    "    input_tensor = Input(shape=(3,img_width,img_height))\n",
    "    base_model = applications.VGG16(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "    top_model.add(Dense(256, activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(1, activation='sigmoid'))\n",
    "    #top_model.load_weights(top_model_weights_path)\n",
    "    model = Model(inputs= base_model.input, outputs= top_model(base_model.output))\n",
    "    model.load_weights(top_model_weights_path)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_image_class(model, file, img_width,img_height):\n",
    "    #model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "    x = load_img(file, target_size=(img_width,img_height))\n",
    "    x = img_to_array(x)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    array = model.predict(x)\n",
    "    class_predicted = model.predict(array)\n",
    "    if class_predicted==1:\n",
    "        print(\"malignant\")\n",
    "    else:\n",
    "        print(\"benign\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'validation'\n",
    "test_dir = 'test'\n",
    "\n",
    "mal_dir = \"Malignant\"\n",
    "ben_dir = \"Benign\"\n",
    "\n",
    "# path to the model weights files.\n",
    "top_model_weights_path = '../bottleneck_fc_model.h5'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "model = get_model(top_model_weights_path, img_width, img_height)\n",
    "\n",
    "for trainValTest in [test_dir]:\n",
    "    actual_mal = [0,0] # true, false\n",
    "    actual_ben = [0,0] # false, true\n",
    "    actual_mal_pred = []\n",
    "    actual_ben_pred = []\n",
    "    \n",
    "    for malBen in [mal_dir,ben_dir]:\n",
    "        cur_path = trainValTest + \"/\" + malBen + \"/\"\n",
    "        for file in progressbar.log_progress(os.listdir(cur_path)[:]):\n",
    "            \n",
    "            if file.endswith(\".jpg\"):\n",
    "                #predict_image_class(model, path_cur_directory+file, img_width,img_height)\n",
    "\n",
    "                path_file = cur_path + file\n",
    "                x = load_img(path_file, target_size=(img_width,img_height))\n",
    "                x = img_to_array(x)\n",
    "                x = np.expand_dims(x, axis=0)\n",
    "                value_prediction = model.predict(x)[0][0]\n",
    "                \n",
    "                if malBen == mal_dir:\n",
    "                    actual_mal_pred += value_prediction\n",
    "                    if value_prediction > 0.5:\n",
    "                        actual_mal[0] += 1\n",
    "                    else:\n",
    "                        actual_mal[1] += 1\n",
    "                else:\n",
    "                    actual_ben_pred += value_prediction\n",
    "                    if value_prediction > 0.5:\n",
    "                        actual_ben[0] += 1\n",
    "                    else:\n",
    "                        actual_ben[1] += 1\n",
    "    print(actual_mal)\n",
    "    print(actual_ben)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(0,len(actual_mal_pred)), actual_mal_pred)\n",
    "plt.show()\n",
    "plt.scatter(np.arange(0,len(actual_ben_pred)), actual_ben_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "1b6bd29af2b14c13aca1d5842c8ce079": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "26b481d34cfe42fdba9159a2e9d396b0": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "2f48355978ac46b3b5ed3f128e1cf4da": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "4f12b2123c234e999b1395b3c07434e5": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "5f04d34f76e14e38b839efbd857c8f4d": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "66fdbad77af04d27b238290048f04531": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "69dfd707635a4664a99535c79e7b37ac": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "6c61d8d442dc4d7c9077f0ce6c304333": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "a8aaf75a1dc74ff3a16f6a21fbec255e": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "b2ba3201d79f4360a8401a630ef38e5c": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "b703345f4b1c4b17bd54ce74f38ac668": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "c054aa439a584c7796cdbb125bad96e3": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "c42f5329c4794988ad69b7030048c54d": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "e50f6109b7994af69c8a7ee74beb5a2a": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "ece0f7a60406473c90f2d96dc6ddb49c": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    },
    "f328663dcfca43afbd813d0e5d490ca0": {
     "views": [
      {
       "cell_index": 4
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
