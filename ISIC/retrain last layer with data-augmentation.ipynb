{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I redo Georges work but with dataaugmentation in the datagenerator. --Janne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to work on the server\n",
    "import os\n",
    "os.environ[\"CUDA DEVICE ORDER\"]=\"PCI BUS ID\"\n",
    "os.environ[\"CUDA VISIBLE DEVICES\"]=\"#gpunum\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'validation', 'bottleneck_features_train.npy', 'bottleneck_features_validation.npy', 'train']\n"
     ]
    }
   ],
   "source": [
    "PATH='/home/jankoo/Project/data1/'\n",
    "files= os.listdir(PATH)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "top_model_weights_path = 'bottleneck_fc_model_jk.h5'\n",
    "train_data_dir = PATH+'train/'\n",
    "validation_data_dir =PATH+ 'validation/'\n",
    "test_dir =PATH+ 'test/'\n",
    "nb_train_samples = 841\n",
    "nb_validation_samples = 373\n",
    "epochs = 50\n",
    "batch_size = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_bottleneck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "                                 rotation_range=360,\n",
    "                                 width_shift_range=0.2,\n",
    "                                 height_shift_range=0.2,\n",
    "                                 shear_range=0.2,\n",
    "                                 zoom_range=0.2,\n",
    "                                 fill_mode='nearest',\n",
    "                                 horizontal_flip=True,\n",
    "                                 vertical_flip=True)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "    np.save('bottleneck_features_train_jk',\n",
    "        bottleneck_features_train)\n",
    "\n",
    "    print(\"done train\")\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    np.save('bottleneck_features_validation_jk',\n",
    "            bottleneck_features_validation)\n",
    "    print(\"done valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nobackup/titans/jankoo/anaconda3/lib/python3.6/site-packages/keras/applications/vgg16.py:184: UserWarning: You are using the TensorFlow backend, yet you are using the Theano image data format convention (`image_data_format=\"channels_first\"`). For best performance, set `image_data_format=\"channels_last\"` in your Keras config at ~/.keras/keras.json.\n",
      "  warnings.warn('You are using the TensorFlow backend, yet you '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 841 images belonging to 2 classes.\n",
      "done train\n",
      "Found 373 images belonging to 2 classes.\n",
      "done valid\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_top_model():\n",
    "    train_data = np.load('bottleneck_features_train_jk.npy')\n",
    "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2+nb_train_samples%2))\n",
    "\n",
    "    validation_data = np.load('bottleneck_features_validation_jk.npy')\n",
    "    validation_labels = np.array([0] * (nb_validation_samples // 2) + \n",
    "                                 [1] * (nb_validation_samples // 2+nb_validation_samples%2))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    print(\"starting fitting\")\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)\n",
    "    print(\"ended fitting and saving\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fitting\n",
      "Train on 841 samples, validate on 373 samples\n",
      "Epoch 1/50\n",
      "841/841 [==============================] - 1s 2ms/step - loss: 0.9621 - acc: 0.5268 - val_loss: 0.6719 - val_acc: 0.5871\n",
      "Epoch 2/50\n",
      "841/841 [==============================] - 0s 330us/step - loss: 0.7080 - acc: 0.5493 - val_loss: 0.8470 - val_acc: 0.5013\n",
      "Epoch 3/50\n",
      "841/841 [==============================] - 0s 323us/step - loss: 0.7057 - acc: 0.5541 - val_loss: 0.6763 - val_acc: 0.5871\n",
      "Epoch 4/50\n",
      "841/841 [==============================] - 0s 372us/step - loss: 0.6942 - acc: 0.5636 - val_loss: 0.6860 - val_acc: 0.5255\n",
      "Epoch 5/50\n",
      "841/841 [==============================] - 0s 360us/step - loss: 0.6745 - acc: 0.5945 - val_loss: 0.7270 - val_acc: 0.5282\n",
      "Epoch 6/50\n",
      "841/841 [==============================] - 0s 324us/step - loss: 0.6544 - acc: 0.5945 - val_loss: 0.6782 - val_acc: 0.5496\n",
      "Epoch 7/50\n",
      "841/841 [==============================] - 0s 327us/step - loss: 0.6556 - acc: 0.6159 - val_loss: 0.6968 - val_acc: 0.5496\n",
      "Epoch 8/50\n",
      "841/841 [==============================] - 0s 366us/step - loss: 0.6398 - acc: 0.6100 - val_loss: 0.7458 - val_acc: 0.5201\n",
      "Epoch 9/50\n",
      "841/841 [==============================] - 0s 379us/step - loss: 0.6276 - acc: 0.6302 - val_loss: 0.6936 - val_acc: 0.6086\n",
      "Epoch 10/50\n",
      "841/841 [==============================] - 0s 376us/step - loss: 0.6214 - acc: 0.6231 - val_loss: 0.6769 - val_acc: 0.6059\n",
      "Epoch 11/50\n",
      "841/841 [==============================] - 0s 345us/step - loss: 0.6055 - acc: 0.6623 - val_loss: 0.7271 - val_acc: 0.5308\n",
      "Epoch 12/50\n",
      "841/841 [==============================] - 0s 370us/step - loss: 0.5886 - acc: 0.6766 - val_loss: 0.6805 - val_acc: 0.6247\n",
      "Epoch 13/50\n",
      "841/841 [==============================] - 0s 382us/step - loss: 0.5807 - acc: 0.6587 - val_loss: 0.6882 - val_acc: 0.6193\n",
      "Epoch 14/50\n",
      "841/841 [==============================] - 0s 357us/step - loss: 0.5695 - acc: 0.7063 - val_loss: 0.6896 - val_acc: 0.6005\n",
      "Epoch 15/50\n",
      "841/841 [==============================] - 0s 304us/step - loss: 0.5565 - acc: 0.6908 - val_loss: 0.7024 - val_acc: 0.6166\n",
      "Epoch 16/50\n",
      "841/841 [==============================] - 0s 337us/step - loss: 0.5454 - acc: 0.6956 - val_loss: 0.7528 - val_acc: 0.5764\n",
      "Epoch 17/50\n",
      "841/841 [==============================] - 0s 339us/step - loss: 0.5269 - acc: 0.6968 - val_loss: 0.7103 - val_acc: 0.6113\n",
      "Epoch 18/50\n",
      "841/841 [==============================] - 0s 327us/step - loss: 0.5289 - acc: 0.7015 - val_loss: 0.8725 - val_acc: 0.5710\n",
      "Epoch 19/50\n",
      "841/841 [==============================] - 0s 338us/step - loss: 0.5090 - acc: 0.7051 - val_loss: 0.9220 - val_acc: 0.5710\n",
      "Epoch 20/50\n",
      "841/841 [==============================] - 0s 321us/step - loss: 0.4959 - acc: 0.7194 - val_loss: 0.8773 - val_acc: 0.5416\n",
      "Epoch 21/50\n",
      "841/841 [==============================] - 0s 342us/step - loss: 0.4809 - acc: 0.7455 - val_loss: 1.0186 - val_acc: 0.5282\n",
      "Epoch 22/50\n",
      "841/841 [==============================] - 0s 355us/step - loss: 0.4747 - acc: 0.7313 - val_loss: 0.8338 - val_acc: 0.5898\n",
      "Epoch 23/50\n",
      "841/841 [==============================] - 0s 343us/step - loss: 0.4645 - acc: 0.7491 - val_loss: 0.8533 - val_acc: 0.5737\n",
      "Epoch 24/50\n",
      "841/841 [==============================] - 0s 355us/step - loss: 0.4533 - acc: 0.7574 - val_loss: 0.7884 - val_acc: 0.5791\n",
      "Epoch 25/50\n",
      "841/841 [==============================] - 0s 317us/step - loss: 0.4449 - acc: 0.7717 - val_loss: 1.1747 - val_acc: 0.5201\n",
      "Epoch 26/50\n",
      "841/841 [==============================] - 0s 296us/step - loss: 0.4602 - acc: 0.7527 - val_loss: 0.8343 - val_acc: 0.5657\n",
      "Epoch 27/50\n",
      "841/841 [==============================] - 0s 355us/step - loss: 0.4322 - acc: 0.7669 - val_loss: 0.8160 - val_acc: 0.5898\n",
      "Epoch 28/50\n",
      "841/841 [==============================] - 0s 337us/step - loss: 0.4238 - acc: 0.7788 - val_loss: 0.8861 - val_acc: 0.5791\n",
      "Epoch 29/50\n",
      "841/841 [==============================] - 0s 337us/step - loss: 0.4253 - acc: 0.7788 - val_loss: 0.8683 - val_acc: 0.5818\n",
      "Epoch 30/50\n",
      "841/841 [==============================] - 0s 338us/step - loss: 0.3974 - acc: 0.7943 - val_loss: 0.9048 - val_acc: 0.5925\n",
      "Epoch 31/50\n",
      "841/841 [==============================] - 0s 327us/step - loss: 0.4059 - acc: 0.7693 - val_loss: 0.9655 - val_acc: 0.5737\n",
      "Epoch 32/50\n",
      "841/841 [==============================] - 0s 360us/step - loss: 0.3950 - acc: 0.7848 - val_loss: 1.0218 - val_acc: 0.5496\n",
      "Epoch 33/50\n",
      "841/841 [==============================] - 0s 359us/step - loss: 0.3830 - acc: 0.8109 - val_loss: 1.0353 - val_acc: 0.5630\n",
      "Epoch 34/50\n",
      "841/841 [==============================] - 0s 363us/step - loss: 0.3793 - acc: 0.8038 - val_loss: 1.1608 - val_acc: 0.5791\n",
      "Epoch 35/50\n",
      "841/841 [==============================] - 0s 345us/step - loss: 0.3889 - acc: 0.8062 - val_loss: 0.9607 - val_acc: 0.5871\n",
      "Epoch 36/50\n",
      "841/841 [==============================] - 0s 378us/step - loss: 0.3804 - acc: 0.7955 - val_loss: 0.9853 - val_acc: 0.5845\n",
      "Epoch 37/50\n",
      "841/841 [==============================] - 0s 370us/step - loss: 0.3717 - acc: 0.8098 - val_loss: 1.0121 - val_acc: 0.5952\n",
      "Epoch 38/50\n",
      "841/841 [==============================] - 0s 320us/step - loss: 0.3381 - acc: 0.8442 - val_loss: 1.1974 - val_acc: 0.5710\n",
      "Epoch 39/50\n",
      "841/841 [==============================] - 0s 341us/step - loss: 0.3672 - acc: 0.8205 - val_loss: 1.0676 - val_acc: 0.5764\n",
      "Epoch 40/50\n",
      "841/841 [==============================] - 0s 345us/step - loss: 0.3298 - acc: 0.8359 - val_loss: 1.0878 - val_acc: 0.5710\n",
      "Epoch 41/50\n",
      "841/841 [==============================] - 0s 349us/step - loss: 0.3361 - acc: 0.8276 - val_loss: 1.1982 - val_acc: 0.5764\n",
      "Epoch 42/50\n",
      "841/841 [==============================] - 0s 352us/step - loss: 0.3451 - acc: 0.8276 - val_loss: 1.1377 - val_acc: 0.5737\n",
      "Epoch 43/50\n",
      "841/841 [==============================] - 0s 348us/step - loss: 0.3420 - acc: 0.8312 - val_loss: 1.3812 - val_acc: 0.5603\n",
      "Epoch 44/50\n",
      "841/841 [==============================] - 0s 356us/step - loss: 0.3253 - acc: 0.8430 - val_loss: 1.2318 - val_acc: 0.5791\n",
      "Epoch 45/50\n",
      "841/841 [==============================] - 0s 333us/step - loss: 0.3273 - acc: 0.8347 - val_loss: 1.2147 - val_acc: 0.5952\n",
      "Epoch 46/50\n",
      "841/841 [==============================] - 0s 347us/step - loss: 0.3248 - acc: 0.8466 - val_loss: 1.2262 - val_acc: 0.5523\n",
      "Epoch 47/50\n",
      "841/841 [==============================] - 0s 338us/step - loss: 0.3071 - acc: 0.8537 - val_loss: 1.2626 - val_acc: 0.5979\n",
      "Epoch 48/50\n",
      "841/841 [==============================] - 0s 355us/step - loss: 0.3017 - acc: 0.8419 - val_loss: 1.6534 - val_acc: 0.5201\n",
      "Epoch 49/50\n",
      "841/841 [==============================] - 0s 334us/step - loss: 0.2908 - acc: 0.8585 - val_loss: 1.2312 - val_acc: 0.5791\n",
      "Epoch 50/50\n",
      "841/841 [==============================] - 0s 326us/step - loss: 0.2944 - acc: 0.8478 - val_loss: 1.4165 - val_acc: 0.5925\n",
      "ended fitting and saving\n"
     ]
    }
   ],
   "source": [
    "train_top_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here comes the fine tunning part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nobackup/titans/jankoo/anaconda3/lib/python3.6/site-packages/keras/applications/vgg16.py:184: UserWarning: You are using the TensorFlow backend, yet you are using the Theano image data format convention (`image_data_format=\"channels_first\"`). For best performance, set `image_data_format=\"channels_last\"` in your Keras config at ~/.keras/keras.json.\n",
      "  warnings.warn('You are using the TensorFlow backend, yet you '\n"
     ]
    }
   ],
   "source": [
    "weights_path = '../keras/models/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "input_tensor = Input(shape=(3,img_width,img_height))\n",
    "base_model = applications.VGG16(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "model = Model(inputs= base_model.input, outputs= top_model(base_model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the first 15 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 3, 150, 150)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 64, 150, 150)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 64, 150, 150)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 75, 75)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 128, 75, 75)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 128, 75, 75)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 128, 37, 37)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 256, 37, 37)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 256, 37, 37)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 256, 37, 37)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 256, 18, 18)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 512, 18, 18)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 512, 18, 18)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 512, 18, 18)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 512, 9, 9)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 512, 9, 9)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 512, 9, 9)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 512, 9, 9)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 512, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "sequential_7 (Sequential)    (None, 1)                 2097665   \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 9,177,089\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        rotation_range=360,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 841 images belonging to 2 classes.\n",
      "Found 373 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#make the generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nobackup/titans/jankoo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  import sys\n",
      "/nobackup/titans/jankoo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=50, validation_data=<keras.pre..., steps_per_epoch=52, validation_steps=373)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "53/52 [==============================] - 17s 322ms/step - loss: 0.6038 - acc: 0.7996 - val_loss: 0.6180 - val_acc: 0.6917\n",
      "Epoch 2/50\n",
      "53/52 [==============================] - 13s 238ms/step - loss: 0.4675 - acc: 0.8162 - val_loss: 0.6751 - val_acc: 0.6327\n",
      "Epoch 3/50\n",
      "53/52 [==============================] - 12s 235ms/step - loss: 0.4466 - acc: 0.8237 - val_loss: 0.7108 - val_acc: 0.6273\n",
      "Epoch 4/50\n",
      "53/52 [==============================] - 13s 243ms/step - loss: 0.4543 - acc: 0.8300 - val_loss: 0.6176 - val_acc: 0.6488\n",
      "Epoch 5/50\n",
      "53/52 [==============================] - 12s 235ms/step - loss: 0.4317 - acc: 0.8307 - val_loss: 0.6481 - val_acc: 0.6381\n",
      "Epoch 6/50\n",
      "53/52 [==============================] - 13s 238ms/step - loss: 0.4302 - acc: 0.8340 - val_loss: 0.7130 - val_acc: 0.6408\n",
      "Epoch 7/50\n",
      "53/52 [==============================] - 12s 230ms/step - loss: 0.4266 - acc: 0.8378 - val_loss: 0.6257 - val_acc: 0.6461\n",
      "Epoch 8/50\n",
      "53/52 [==============================] - 12s 236ms/step - loss: 0.4259 - acc: 0.8408 - val_loss: 0.6673 - val_acc: 0.6354\n",
      "Epoch 9/50\n",
      "53/52 [==============================] - 13s 242ms/step - loss: 0.4312 - acc: 0.8366 - val_loss: 0.6208 - val_acc: 0.6515\n",
      "Epoch 10/50\n",
      "53/52 [==============================] - 13s 239ms/step - loss: 0.4267 - acc: 0.8340 - val_loss: 0.6856 - val_acc: 0.6381\n",
      "Epoch 11/50\n",
      "53/52 [==============================] - 12s 234ms/step - loss: 0.4272 - acc: 0.8285 - val_loss: 0.6564 - val_acc: 0.6488\n",
      "Epoch 12/50\n",
      "53/52 [==============================] - 13s 249ms/step - loss: 0.4122 - acc: 0.8307 - val_loss: 0.7912 - val_acc: 0.6327\n",
      "Epoch 13/50\n",
      "53/52 [==============================] - 13s 241ms/step - loss: 0.4154 - acc: 0.8386 - val_loss: 0.7063 - val_acc: 0.6461\n",
      "Epoch 14/50\n",
      "53/52 [==============================] - 12s 231ms/step - loss: 0.4261 - acc: 0.8314 - val_loss: 0.6521 - val_acc: 0.6542\n",
      "Epoch 15/50\n",
      "53/52 [==============================] - 12s 236ms/step - loss: 0.4101 - acc: 0.8374 - val_loss: 0.8077 - val_acc: 0.6327\n",
      "Epoch 16/50\n",
      "53/52 [==============================] - 13s 239ms/step - loss: 0.4170 - acc: 0.8378 - val_loss: 0.5910 - val_acc: 0.6971\n",
      "Epoch 17/50\n",
      "53/52 [==============================] - 13s 245ms/step - loss: 0.4045 - acc: 0.8390 - val_loss: 0.6047 - val_acc: 0.6810\n",
      "Epoch 18/50\n",
      "53/52 [==============================] - 13s 236ms/step - loss: 0.4048 - acc: 0.8367 - val_loss: 0.6254 - val_acc: 0.6783\n",
      "Epoch 19/50\n",
      "53/52 [==============================] - 13s 251ms/step - loss: 0.4060 - acc: 0.8405 - val_loss: 0.5658 - val_acc: 0.7105\n",
      "Epoch 20/50\n",
      "53/52 [==============================] - 15s 276ms/step - loss: 0.4136 - acc: 0.8385 - val_loss: 0.7821 - val_acc: 0.6381\n",
      "Epoch 21/50\n",
      "53/52 [==============================] - 13s 239ms/step - loss: 0.4126 - acc: 0.8390 - val_loss: 0.5873 - val_acc: 0.7105\n",
      "Epoch 22/50\n",
      "53/52 [==============================] - 13s 237ms/step - loss: 0.4169 - acc: 0.8322 - val_loss: 0.6324 - val_acc: 0.6810\n",
      "Epoch 23/50\n",
      "53/52 [==============================] - 12s 235ms/step - loss: 0.4039 - acc: 0.8459 - val_loss: 0.6655 - val_acc: 0.6729\n",
      "Epoch 24/50\n",
      "53/52 [==============================] - 12s 235ms/step - loss: 0.4175 - acc: 0.8322 - val_loss: 0.5525 - val_acc: 0.7292\n",
      "Epoch 25/50\n",
      "53/52 [==============================] - 13s 236ms/step - loss: 0.4069 - acc: 0.8439 - val_loss: 0.6144 - val_acc: 0.6702\n",
      "Epoch 26/50\n",
      "53/52 [==============================] - 13s 237ms/step - loss: 0.3846 - acc: 0.8331 - val_loss: 0.6890 - val_acc: 0.6756\n",
      "Epoch 27/50\n",
      "53/52 [==============================] - 14s 256ms/step - loss: 0.4218 - acc: 0.8315 - val_loss: 0.6218 - val_acc: 0.6810\n",
      "Epoch 28/50\n",
      "53/52 [==============================] - 13s 237ms/step - loss: 0.3980 - acc: 0.8324 - val_loss: 0.5629 - val_acc: 0.7212\n",
      "Epoch 29/50\n",
      "53/52 [==============================] - 13s 239ms/step - loss: 0.4172 - acc: 0.8352 - val_loss: 0.6607 - val_acc: 0.6756\n",
      "Epoch 30/50\n",
      "53/52 [==============================] - 12s 232ms/step - loss: 0.4036 - acc: 0.8434 - val_loss: 0.7038 - val_acc: 0.6649\n",
      "Epoch 31/50\n",
      "53/52 [==============================] - 13s 237ms/step - loss: 0.3956 - acc: 0.8490 - val_loss: 0.6588 - val_acc: 0.6810\n",
      "Epoch 32/50\n",
      "53/52 [==============================] - 12s 236ms/step - loss: 0.4215 - acc: 0.8294 - val_loss: 0.6680 - val_acc: 0.6756\n",
      "Epoch 33/50\n",
      "53/52 [==============================] - 12s 234ms/step - loss: 0.4042 - acc: 0.8389 - val_loss: 0.6932 - val_acc: 0.6676\n",
      "Epoch 34/50\n",
      "53/52 [==============================] - 13s 236ms/step - loss: 0.3827 - acc: 0.8448 - val_loss: 0.6136 - val_acc: 0.6756\n",
      "Epoch 35/50\n",
      "53/52 [==============================] - 12s 235ms/step - loss: 0.4027 - acc: 0.8425 - val_loss: 0.6762 - val_acc: 0.6810\n",
      "Epoch 36/50\n",
      "53/52 [==============================] - 13s 238ms/step - loss: 0.3882 - acc: 0.8478 - val_loss: 0.5987 - val_acc: 0.7051 - loss: 0.3779 - acc: 0.\n",
      "Epoch 37/50\n",
      "53/52 [==============================] - 13s 241ms/step - loss: 0.3942 - acc: 0.8366 - val_loss: 0.6849 - val_acc: 0.6783\n",
      "Epoch 38/50\n",
      "53/52 [==============================] - 13s 236ms/step - loss: 0.3941 - acc: 0.8381 - val_loss: 0.5871 - val_acc: 0.6944\n",
      "Epoch 39/50\n",
      "53/52 [==============================] - 12s 231ms/step - loss: 0.4001 - acc: 0.8363 - val_loss: 0.6310 - val_acc: 0.6756\n",
      "Epoch 40/50\n",
      "53/52 [==============================] - 13s 241ms/step - loss: 0.4046 - acc: 0.8411 - val_loss: 0.7185 - val_acc: 0.6461\n",
      "Epoch 41/50\n",
      "53/52 [==============================] - 13s 236ms/step - loss: 0.4099 - acc: 0.8341 - val_loss: 0.5565 - val_acc: 0.7239\n",
      "Epoch 42/50\n",
      "53/52 [==============================] - 13s 237ms/step - loss: 0.3964 - acc: 0.8445 - val_loss: 0.5750 - val_acc: 0.7212\n",
      "Epoch 43/50\n",
      "53/52 [==============================] - 12s 233ms/step - loss: 0.3693 - acc: 0.8457 - val_loss: 0.7820 - val_acc: 0.6515\n",
      "Epoch 44/50\n",
      "53/52 [==============================] - 13s 236ms/step - loss: 0.4051 - acc: 0.8400 - val_loss: 0.6031 - val_acc: 0.6836\n",
      "Epoch 45/50\n",
      "53/52 [==============================] - 13s 242ms/step - loss: 0.3864 - acc: 0.8424 - val_loss: 0.6580 - val_acc: 0.6836\n",
      "Epoch 46/50\n",
      "53/52 [==============================] - 12s 232ms/step - loss: 0.3784 - acc: 0.8488 - val_loss: 0.5675 - val_acc: 0.7292\n",
      "Epoch 47/50\n",
      "53/52 [==============================] - 12s 233ms/step - loss: 0.3647 - acc: 0.8492 - val_loss: 0.6522 - val_acc: 0.6971\n",
      "Epoch 48/50\n",
      "53/52 [==============================] - 13s 246ms/step - loss: 0.3750 - acc: 0.8513 - val_loss: 0.6977 - val_acc: 0.6836\n",
      "Epoch 49/50\n",
      "53/52 [==============================] - 13s 237ms/step - loss: 0.3742 - acc: 0.8448 - val_loss: 0.6613 - val_acc: 0.6863\n",
      "Epoch 50/50\n",
      "53/52 [==============================] - 12s 233ms/step - loss: 0.3737 - acc: 0.8458 - val_loss: 0.6691 - val_acc: 0.6783\n"
     ]
    }
   ],
   "source": [
    "# fine-tune the model\n",
    "model_history=model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('last_and_finetuned_jk.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
