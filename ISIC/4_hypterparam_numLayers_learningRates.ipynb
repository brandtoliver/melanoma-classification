{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "import os\n",
    "os.chdir(\"/home/ubuntu/data/\")\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Image, display, clear_output\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def tune_layers_learningRate(num_fixed_layers, num_epochs=20, learning_rate=None):\n",
    "    \n",
    "    # path to the model weights files.\n",
    "    weights_path = '../vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "    top_model_weights_path = '../download/5_binary_crossentropy_rmsprop.h5'\n",
    "    # dimensions of our images.\n",
    "    img_width, img_height = 150, 150\n",
    "\n",
    "    train_data_dir = 'train'\n",
    "    validation_data_dir = 'validation'\n",
    "    test_dir = 'test'\n",
    "    nb_train_samples = 800\n",
    "    nb_validation_samples = 370\n",
    "    epochs = num_epochs\n",
    "    batch_size = 5\n",
    "\n",
    "    input_tensor = Input(shape=(3,img_width,img_height))\n",
    "    base_model = applications.VGG16(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
    "    top_model = Sequential()\n",
    "    top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "    top_model.add(Dense(256, activation='relu'))\n",
    "    top_model.add(Dropout(0.5))\n",
    "    top_model.add(Dense(1, activation='sigmoid'))\n",
    "    top_model.load_weights(top_model_weights_path)\n",
    "    model = Model(inputs= base_model.input, outputs= top_model(base_model.output))\n",
    "\n",
    "    # set the latest x layers (up to the last conv block)\n",
    "    # to non-trainable (weights will not be updated)\n",
    "    for layer in model.layers[:num_fixed_layers]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # compile the model with a SGD/momentum optimizer\n",
    "    # and a very slow learning rate.\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # prepare data augmentation configuration\n",
    "    train_datagen = ImageDataGenerator(\n",
    "            rescale=1. / 255,\n",
    "            rotation_range=180,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest')\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    \n",
    "    # fine-tune the model\n",
    "    time_start = time.time()\n",
    "    history = model.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=nb_train_samples,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        nb_val_samples=nb_validation_samples)\n",
    "    time_end = time.time()\n",
    "    print(int(time_end - time_start))\n",
    "\n",
    "    file_prefix = \"../download/4_\"+str(num_fixed_layers)\n",
    "    weights_file_title = file_prefix + \".h5\"\n",
    "    model.save_weights( weights_file_title )\n",
    "    title = \"fixed layers: \"+ str(num_fixed_layers)\n",
    "    plot_nicely(history, file_prefix)\n",
    "    \n",
    "    return history, title\n",
    "    \n",
    "def plot_nicely(history, filename_prefix=\"\"):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    \n",
    "    time_now = datetime.datetime.now()\n",
    "    time_string = str(time_now.hour) + str(time_now.minute)\n",
    "    fileName1 = filename_prefix + \"_\" + time_string + \"_1.png\"\n",
    "    fileName2 = filename_prefix + \"_\" + time_string + \"_2.png\"\n",
    "    \n",
    "    plt.savefig(fileName1)\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.savefig(fileName2)\n",
    "    plt.show()\n",
    "    \n",
    "    clear_output(True)\n",
    "    display(Image(filename=fileName1))\n",
    "    display(Image(filename=fileName2))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/applications/vgg16.py:182: UserWarning: You are using the TensorFlow backend, yet you are using the Theano image data format convention (`image_data_format=\"channels_first\"`). For best performance, set `image_data_format=\"channels_last\"` in your Keras config at ~/.keras/keras.json.\n",
      "  warnings.warn('You are using the TensorFlow backend, yet you '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 841 images belonging to 2 classes.\n",
      "Found 373 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:70: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:70: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., steps_per_epoch=160, epochs=110, validation_steps=370, validation_data=<keras.pre...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/110\n",
      "159/160 [============================>.] - ETA: 0s - loss: 0.4873 - acc: 0.8176"
     ]
    }
   ],
   "source": [
    "fixed_layers_array = [8, 10, 13, 15]\n",
    "num_epochs = 110\n",
    "\n",
    "title_array = []\n",
    "history_array = []\n",
    "for num_fixed in fixed_layers_array:\n",
    "    history, title = tune_layers_learningRate(num_fixed, num_epochs)\n",
    "    history_array += [history]\n",
    "    title_array += [title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shared_xy(history_array, title_array, filename_prefix=\"\"):\n",
    "    time_now = datetime.datetime.now()\n",
    "    time_string = str(time_now.hour) + str(time_now.minute)\n",
    "    fileName1 = filename_prefix + \"_\" + time_string + \"_1.png\"\n",
    "    fileName2 = filename_prefix + \"_\" + time_string + \"_2.png\"\n",
    "    \n",
    "    # plot acc\n",
    "    f, axarr = plt.subplots(len(history_array), sharex=True, sharey=True, figsize=(10,10))\n",
    "    for a,history in enumerate(history_array):\n",
    "        axarr[a].plot(history.history['acc'])\n",
    "        axarr[a].plot(history.history['val_acc'])\n",
    "        axarr[a].set_title(title_array[a])\n",
    "        axarr[a].set_ylabel('accuracy')\n",
    "        axarr[a].legend(['train', 'test'], loc='upper left')\n",
    "    plt.suptitle('model accuracy')\n",
    "    axarr[-1].set_xlabel('epoch')\n",
    "    f.subplots_adjust(hspace=0.3)\n",
    "    plt.savefig(fileName1)\n",
    "    plt.show()\n",
    "\n",
    "    # plot loss\n",
    "    f, axarr = plt.subplots(len(history_array), sharex=True, sharey=True, figsize=(10,10))\n",
    "    for a,history in enumerate(history_array):\n",
    "        axarr[a].plot(history.history['loss'])\n",
    "        axarr[a].plot(history.history['val_loss'])\n",
    "        axarr[a].set_title(title_array[a])\n",
    "        axarr[a].set_ylabel('loss')\n",
    "        axarr[a].legend(['train', 'test'], loc='upper left')\n",
    "    plt.suptitle('model loss')\n",
    "    axarr[-1].set_xlabel('epoch')\n",
    "    f.subplots_adjust(hspace=0.3)\n",
    "    plt.savefig(fileName2)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    clear_output(True)\n",
    "    display(Image(filename=fileName1))\n",
    "    display(Image(filename=fileName2))\n",
    "    return\n",
    "\n",
    "plot_shared_xy(history_array, title_array, \"../download/4_shared\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
