{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook it is shown how we get our results. The main idea of our method is to do transfer-learning. We did download the weights corresponding to the VG16 model and then we first retrained the last layer to our first classes. Next we did finetune the last convolutional layers, taking care not do get overfitting by using a small learning rate.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this are the packages we used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, Input\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "import os\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import progressbar\n",
    "from IPython.display import Image, display, clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path to the datafolder and the parameters. The data folder is divided in 3 subfolders test, train and validation, containing 20%, 60% and 20% of the data respectively. Each of  this folder is oneach turn split in two subfolders again, one malignant and wan benign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['validation', 'train', 'test']\n"
     ]
    }
   ],
   "source": [
    "#test that your are where you are\n",
    "PATH=\"/home/ubuntu/data/\"\n",
    "folders=os.listdir(PATH)\n",
    "print(folders)\n",
    "os.chdir(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "train_data_dir = PATH+'train/'\n",
    "validation_data_dir =PATH+ 'validation/'\n",
    "test_dir =PATH+ 'test/'\n",
    "nb_train_samples = 832\n",
    "nb_validation_samples = 368\n",
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the following data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we saved the bottleneck features, that is we took the VGG16 network. We took pathches of our data, aumentated it and loaded it through VG16 except the last layer. We did save the outcome of the network in in the bottle neck features. So we got bottleneck features for the train and validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_bottlebeck_features():\n",
    "    #datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "    np.save('bottleneck_features_train',\n",
    "        bottleneck_features_train)\n",
    "\n",
    "    print(\"done train\")\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    np.save('bottleneck_features_validation',\n",
    "            bottleneck_features_validation)\n",
    "    print(\"done valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used this bottleneck features as input of our top model. And we trained this top model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_top_model():\n",
    "    train_data = np.load('bottleneck_features_train.npy')\n",
    "    train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2+nb_train_samples%2))\n",
    "\n",
    "    validation_data = np.load('bottleneck_features_validation.npy')\n",
    "    validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2+nb_validation_samples%2))\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    print(\"starting fitting\")\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)\n",
    "    print(\"ended fitting and saving\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call our functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/applications/vgg16.py:182: UserWarning: You are using the TensorFlow backend, yet you are using the Theano image data format convention (`image_data_format=\"channels_first\"`). For best performance, set `image_data_format=\"channels_last\"` in your Keras config at ~/.keras/keras.json.\n",
      "  warnings.warn('You are using the TensorFlow backend, yet you '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 841 images belonging to 2 classes.\n",
      "done train\n",
      "Found 373 images belonging to 2 classes.\n",
      "done valid\n"
     ]
    }
   ],
   "source": [
    "save_bottlebeck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting fitting\n",
      "Train on 832 samples, validate on 368 samples\n",
      "Epoch 1/50\n",
      "832/832 [==============================] - 0s - loss: 1.0369 - acc: 0.5012 - val_loss: 0.6810 - val_acc: 0.5380\n",
      "Epoch 2/50\n",
      "832/832 [==============================] - 0s - loss: 0.7093 - acc: 0.5421 - val_loss: 0.7777 - val_acc: 0.5136\n",
      "Epoch 3/50\n",
      "832/832 [==============================] - 0s - loss: 0.7044 - acc: 0.5553 - val_loss: 0.7077 - val_acc: 0.5299\n",
      "Epoch 4/50\n",
      "832/832 [==============================] - 0s - loss: 0.6972 - acc: 0.5312 - val_loss: 0.7254 - val_acc: 0.5054\n",
      "Epoch 5/50\n",
      "832/832 [==============================] - 0s - loss: 0.6897 - acc: 0.5577 - val_loss: 0.7016 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "832/832 [==============================] - 0s - loss: 0.6703 - acc: 0.5901 - val_loss: 0.6985 - val_acc: 0.5027\n",
      "Epoch 7/50\n",
      "832/832 [==============================] - 0s - loss: 0.6700 - acc: 0.5601 - val_loss: 0.6700 - val_acc: 0.5734\n",
      "Epoch 8/50\n",
      "832/832 [==============================] - 0s - loss: 0.6584 - acc: 0.6106 - val_loss: 0.6812 - val_acc: 0.5245\n",
      "Epoch 9/50\n",
      "832/832 [==============================] - 0s - loss: 0.6479 - acc: 0.5962 - val_loss: 0.7044 - val_acc: 0.5625\n",
      "Epoch 10/50\n",
      "832/832 [==============================] - 0s - loss: 0.6368 - acc: 0.6118 - val_loss: 0.7223 - val_acc: 0.4918\n",
      "Epoch 11/50\n",
      "832/832 [==============================] - 0s - loss: 0.6404 - acc: 0.6226 - val_loss: 0.8173 - val_acc: 0.5353\n",
      "Epoch 12/50\n",
      "832/832 [==============================] - 0s - loss: 0.6174 - acc: 0.6394 - val_loss: 0.7989 - val_acc: 0.4946\n",
      "Epoch 13/50\n",
      "832/832 [==============================] - 0s - loss: 0.6006 - acc: 0.6502 - val_loss: 0.7128 - val_acc: 0.5245\n",
      "Epoch 14/50\n",
      "832/832 [==============================] - 0s - loss: 0.6049 - acc: 0.6599 - val_loss: 0.7451 - val_acc: 0.5679\n",
      "Epoch 15/50\n",
      "832/832 [==============================] - 0s - loss: 0.5818 - acc: 0.6683 - val_loss: 0.7577 - val_acc: 0.5109\n",
      "Epoch 16/50\n",
      "832/832 [==============================] - 0s - loss: 0.5727 - acc: 0.6743 - val_loss: 0.7825 - val_acc: 0.5408\n",
      "Epoch 17/50\n",
      "832/832 [==============================] - 0s - loss: 0.5703 - acc: 0.6779 - val_loss: 0.7777 - val_acc: 0.5598\n",
      "Epoch 18/50\n",
      "832/832 [==============================] - 0s - loss: 0.5541 - acc: 0.6971 - val_loss: 0.7836 - val_acc: 0.5571\n",
      "Epoch 19/50\n",
      "832/832 [==============================] - 0s - loss: 0.5335 - acc: 0.7043 - val_loss: 0.8029 - val_acc: 0.5136\n",
      "Epoch 20/50\n",
      "832/832 [==============================] - 0s - loss: 0.5320 - acc: 0.7115 - val_loss: 0.7961 - val_acc: 0.5707\n",
      "Epoch 21/50\n",
      "832/832 [==============================] - 0s - loss: 0.5062 - acc: 0.7308 - val_loss: 0.8680 - val_acc: 0.5788\n",
      "Epoch 22/50\n",
      "832/832 [==============================] - 0s - loss: 0.5066 - acc: 0.7344 - val_loss: 0.9116 - val_acc: 0.5054\n",
      "Epoch 23/50\n",
      "832/832 [==============================] - 0s - loss: 0.5000 - acc: 0.7320 - val_loss: 0.8385 - val_acc: 0.5380\n",
      "Epoch 24/50\n",
      "832/832 [==============================] - 0s - loss: 0.4951 - acc: 0.7356 - val_loss: 0.9347 - val_acc: 0.5190\n",
      "Epoch 25/50\n",
      "832/832 [==============================] - 0s - loss: 0.4846 - acc: 0.7500 - val_loss: 0.8734 - val_acc: 0.5380\n",
      "Epoch 26/50\n",
      "832/832 [==============================] - 0s - loss: 0.4826 - acc: 0.7260 - val_loss: 0.9448 - val_acc: 0.5163\n",
      "Epoch 27/50\n",
      "832/832 [==============================] - 0s - loss: 0.4622 - acc: 0.7380 - val_loss: 0.9029 - val_acc: 0.5571\n",
      "Epoch 28/50\n",
      "832/832 [==============================] - 0s - loss: 0.4599 - acc: 0.7452 - val_loss: 0.9650 - val_acc: 0.5380\n",
      "Epoch 29/50\n",
      "832/832 [==============================] - 0s - loss: 0.4322 - acc: 0.7909 - val_loss: 0.9599 - val_acc: 0.5489\n",
      "Epoch 30/50\n",
      "832/832 [==============================] - 0s - loss: 0.4444 - acc: 0.7716 - val_loss: 0.9616 - val_acc: 0.5652\n",
      "Epoch 31/50\n",
      "832/832 [==============================] - 0s - loss: 0.4330 - acc: 0.7620 - val_loss: 0.9711 - val_acc: 0.5435\n",
      "Epoch 32/50\n",
      "832/832 [==============================] - 0s - loss: 0.4234 - acc: 0.7897 - val_loss: 1.0810 - val_acc: 0.5435\n",
      "Epoch 33/50\n",
      "832/832 [==============================] - 0s - loss: 0.4248 - acc: 0.7656 - val_loss: 1.0155 - val_acc: 0.5082\n",
      "Epoch 34/50\n",
      "832/832 [==============================] - 0s - loss: 0.4226 - acc: 0.7861 - val_loss: 1.0965 - val_acc: 0.5054\n",
      "Epoch 35/50\n",
      "832/832 [==============================] - 0s - loss: 0.4164 - acc: 0.7885 - val_loss: 1.1557 - val_acc: 0.5027\n",
      "Epoch 36/50\n",
      "832/832 [==============================] - 0s - loss: 0.4068 - acc: 0.7969 - val_loss: 1.1101 - val_acc: 0.5217\n",
      "Epoch 37/50\n",
      "832/832 [==============================] - 0s - loss: 0.3822 - acc: 0.8017 - val_loss: 1.1004 - val_acc: 0.5489\n",
      "Epoch 38/50\n",
      "832/832 [==============================] - 0s - loss: 0.3804 - acc: 0.8029 - val_loss: 1.1418 - val_acc: 0.5462\n",
      "Epoch 39/50\n",
      "832/832 [==============================] - 0s - loss: 0.3737 - acc: 0.8101 - val_loss: 1.1745 - val_acc: 0.5516\n",
      "Epoch 40/50\n",
      "832/832 [==============================] - 0s - loss: 0.3659 - acc: 0.8233 - val_loss: 1.2010 - val_acc: 0.5707\n",
      "Epoch 41/50\n",
      "832/832 [==============================] - 0s - loss: 0.3783 - acc: 0.7873 - val_loss: 1.2079 - val_acc: 0.5136\n",
      "Epoch 42/50\n",
      "832/832 [==============================] - 0s - loss: 0.3481 - acc: 0.8197 - val_loss: 1.1904 - val_acc: 0.5272\n",
      "Epoch 43/50\n",
      "832/832 [==============================] - 0s - loss: 0.3396 - acc: 0.8245 - val_loss: 1.2068 - val_acc: 0.5217\n",
      "Epoch 44/50\n",
      "832/832 [==============================] - 0s - loss: 0.3354 - acc: 0.8365 - val_loss: 1.2730 - val_acc: 0.5326\n",
      "Epoch 45/50\n",
      "832/832 [==============================] - 0s - loss: 0.3475 - acc: 0.8209 - val_loss: 1.4130 - val_acc: 0.5245\n",
      "Epoch 46/50\n",
      "832/832 [==============================] - 0s - loss: 0.3287 - acc: 0.8257 - val_loss: 1.4226 - val_acc: 0.5109\n",
      "Epoch 47/50\n",
      "832/832 [==============================] - 0s - loss: 0.3289 - acc: 0.8522 - val_loss: 1.5260 - val_acc: 0.5109\n",
      "Epoch 48/50\n",
      "832/832 [==============================] - 0s - loss: 0.3233 - acc: 0.8305 - val_loss: 1.3941 - val_acc: 0.5462\n",
      "Epoch 49/50\n",
      "832/832 [==============================] - 0s - loss: 0.3342 - acc: 0.8257 - val_loss: 1.3169 - val_acc: 0.5435\n",
      "Epoch 50/50\n",
      "832/832 [==============================] - 0s - loss: 0.3100 - acc: 0.8606 - val_loss: 1.5176 - val_acc: 0.5326\n",
      "ended fitting and saving\n"
     ]
    }
   ],
   "source": [
    "train_top_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check that we are doing it correctly we have a function that can predict what we see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image_class(file):\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "    x = load_img(file, target_size=(img_width,img_height))\n",
    "    x = img_to_array(x)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    array = model.predict(x)\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=array.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.load_weights(top_model_weights_path)\n",
    "    class_predicted = model.predict_classes(array)\n",
    "    if class_predicted==1:\n",
    "        print(\"malignant\")\n",
    "    else:\n",
    "        print(\"benign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nex we fine tune the last convolutional layers of VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/applications/vgg16.py:182: UserWarning: You are using the TensorFlow backend, yet you are using the Theano image data format convention (`image_data_format=\"channels_first\"`). For best performance, set `image_data_format=\"channels_last\"` in your Keras config at ~/.keras/keras.json.\n",
      "  warnings.warn('You are using the TensorFlow backend, yet you '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 841 images belonging to 2 classes.\n",
      "Found 373 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# path to the model weights files.\n",
    "weights_path = '../vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'validation'\n",
    "test_dir = 'test'\n",
    "nb_train_samples = 800\n",
    "nb_validation_samples = 370\n",
    "epochs = 20\n",
    "batch_size = 5\n",
    "\n",
    "input_tensor = Input(shape=(3,img_width,img_height))\n",
    "base_model = applications.VGG16(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "model = Model(inputs= base_model.input, outputs= top_model(base_model.output))\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model with a SGD/momentum optimizer\n",
    "# and a very slow learning rate.\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        rotation_range=180,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  import sys\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., steps_per_epoch=160, epochs=20, validation_steps=370)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "160/160 [==============================] - 37s - loss: 0.5536 - acc: 0.7863 - val_loss: 0.6570 - val_acc: 0.6303\n",
      "Epoch 2/20\n",
      "160/160 [==============================] - 36s - loss: 0.4723 - acc: 0.8187 - val_loss: 0.9106 - val_acc: 0.6234\n",
      "Epoch 3/20\n",
      "160/160 [==============================] - 35s - loss: 0.4584 - acc: 0.8350 - val_loss: 0.6646 - val_acc: 0.6315\n",
      "Epoch 4/20\n",
      "160/160 [==============================] - 35s - loss: 0.4713 - acc: 0.8287 - val_loss: 0.7873 - val_acc: 0.6272\n",
      "Epoch 5/20\n",
      "160/160 [==============================] - 36s - loss: 0.4598 - acc: 0.8225 - val_loss: 0.6958 - val_acc: 0.6326\n",
      "Epoch 6/20\n",
      "160/160 [==============================] - 35s - loss: 0.4631 - acc: 0.8400 - val_loss: 0.7763 - val_acc: 0.6228\n",
      "Epoch 7/20\n",
      "160/160 [==============================] - 35s - loss: 0.4525 - acc: 0.8212 - val_loss: 0.6661 - val_acc: 0.6402\n",
      "Epoch 8/20\n",
      "160/160 [==============================] - 35s - loss: 0.4429 - acc: 0.8337 - val_loss: 0.7745 - val_acc: 0.6293\n",
      "Epoch 9/20\n",
      "160/160 [==============================] - 35s - loss: 0.4461 - acc: 0.8362 - val_loss: 0.6447 - val_acc: 0.6364\n",
      "Epoch 10/20\n",
      "160/160 [==============================] - 35s - loss: 0.4292 - acc: 0.8325 - val_loss: 0.7606 - val_acc: 0.6370\n",
      "Epoch 11/20\n",
      "160/160 [==============================] - 36s - loss: 0.4224 - acc: 0.8350 - val_loss: 0.6858 - val_acc: 0.6511\n",
      "Epoch 12/20\n",
      "160/160 [==============================] - 35s - loss: 0.4433 - acc: 0.8150 - val_loss: 0.7015 - val_acc: 0.6435\n",
      "Epoch 13/20\n",
      "160/160 [==============================] - 36s - loss: 0.4031 - acc: 0.8475 - val_loss: 0.6408 - val_acc: 0.6821\n",
      "Epoch 14/20\n",
      "160/160 [==============================] - 35s - loss: 0.4051 - acc: 0.8487 - val_loss: 0.9276 - val_acc: 0.6293\n",
      "Epoch 15/20\n",
      "160/160 [==============================] - 36s - loss: 0.4492 - acc: 0.7988 - val_loss: 0.7661 - val_acc: 0.6293\n",
      "Epoch 16/20\n",
      "160/160 [==============================] - 36s - loss: 0.4373 - acc: 0.8350 - val_loss: 0.6712 - val_acc: 0.6916\n",
      "Epoch 17/20\n",
      "160/160 [==============================] - 36s - loss: 0.4290 - acc: 0.8300 - val_loss: 0.7810 - val_acc: 0.6435\n",
      "Epoch 18/20\n",
      "160/160 [==============================] - 36s - loss: 0.4440 - acc: 0.8375 - val_loss: 0.6094 - val_acc: 0.6929\n",
      "Epoch 19/20\n",
      "160/160 [==============================] - 36s - loss: 0.4277 - acc: 0.8388 - val_loss: 0.6466 - val_acc: 0.6560\n",
      "Epoch 20/20\n",
      "160/160 [==============================] - 35s - loss: 0.4165 - acc: 0.8287 - val_loss: 0.6501 - val_acc: 0.6679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2db1f06cc0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune the model\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    samples_per_epoch=nb_train_samples,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    nb_val_samples=nb_validation_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anylizing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is not such a good measure. Because of the nature of benign and malignant it is very important not to have too many false positives, i.e., too often diagnose malignant while it is benign. Therefore, we made the confucion matrix and the receiver operating characteristic and found an area under curve of 0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image_class(model, path_file, img_width,img_height):\n",
    "    \"\"\"returns class in binary classification.\n",
    "    \"\"\"\n",
    "    x = load_img(path_file, target_size=(img_width,img_height))\n",
    "    x = img_to_array(x)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    value_prediction = model.predict(x)[0][0]\n",
    "    return value_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7149fe079ab4f079c06be4b1d340b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=70)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84a11cf544c49eea919d280dbd8a34b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HTML(value=''), IntProgress(value=0, max=234)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "category_array = [\"Malignant\", \"Benign\"]\n",
    "for trainValTest in [test_dir]:\n",
    "    \"\"\"\n",
    "    array:\n",
    "    0 actual class malignant\n",
    "    1 actual class benign\n",
    "    \"\"\"\n",
    "    confusion_matrix = [[0,0],[0,0]] \n",
    "    pred_array = [[],[]]\n",
    "    for a, category in enumerate(category_array):\n",
    "        cur_path = trainValTest + \"/\" + category + \"/\"\n",
    "        for file in progressbar.log_progress(os.listdir(cur_path)[:]):\n",
    "            if file.endswith(\".jpg\"):\n",
    "                path_file = cur_path + file\n",
    "                value_prediction = predict_image_class(model, path_file, img_width, img_height)\n",
    "                pred_array[a] += [value_prediction]\n",
    "                if value_prediction > 0.5:\n",
    "                    confusion_matrix[a][0] += 1\n",
    "                else:\n",
    "                    confusion_matrix[a][1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 63]\n",
      "[3, 231]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix[0])\n",
    "print(confusion_matrix[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7828947368421053 0.7 0.7857142857142857 0.175\n"
     ]
    }
   ],
   "source": [
    "TP = confusion_matrix[0][0]\n",
    "FP = confusion_matrix[0][1]\n",
    "FN = confusion_matrix[1][0]\n",
    "TN = confusion_matrix[1][1]\n",
    "\n",
    "AC = (TP+TN) / (TP+FP+TN+FN)#accuracy\n",
    "SE = TP / (TP+FN)#sensitivity\n",
    "SP = TN / (TN+FP)#specitifity\n",
    "DI = (2*TP) / (2*TP + FN + FP)#dice coefficient\n",
    "\n",
    "print(AC,SE,SP,DI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the roc curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmqKhCCGEUNN/Ab5bnCSAOdZ5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d95747ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_true_0 = np.ones(len(pred_array[0]))\n",
    "y_true_1 = np.zeros(len(pred_array[1]))\n",
    "y_true = np.concatenate([y_true_0, y_true_1],axis=0)\n",
    "y_score = np.concatenate(pred_array, axis=0)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
