{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import ipdb\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import csv\n",
    "import copy\n",
    "import cv2\n",
    "import glob\n",
    "import tensorflow\n",
    "from PIL import Image\n",
    "\n",
    "from IPython.core.debugger import Tracer\n",
    "#Tracer()() #this one triggers the debugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define constants\n",
    "CONTOUR_AREA_THRESH = 100\n",
    "VIGNETTE_THRESH = 90\n",
    "BLACK_THRESH = 50\n",
    "CIRCLE_THRESH = 20\n",
    "# FILT_THRESH = 170\n",
    "GAUSS_THRESH = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a Matlab like struct class\n",
    "class MATLABstruct():\n",
    "\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###################### FUNCTIONS #########################\n",
    "def make2DGaussian(size, radius = 3, center = None):\n",
    "    \"\"\" Make a square gaussian kernel.\n",
    "    size is the length of a side of the square\n",
    "    radius is full-width-half-maximum, which\n",
    "    can be thought of as an effective radius.\n",
    "    \"\"\"\n",
    "    x = np.arange(0, size, 1, float)\n",
    "    y = x[:,np.newaxis]\n",
    "\n",
    "    if center is None:\n",
    "        x0 = y0 = size // 2\n",
    "    else:\n",
    "        x0 = center[0]\n",
    "        y0 = center[1]\n",
    "\n",
    "    gauss = np.exp(-4*np.log(2) * ((x-x0)**2 + (y-y0)**2) / radius**2)\n",
    "    return gauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def circleCrop(img, orig, radiusOption = 0):\n",
    "    # radius = 0 means vignetting is present, radius = 1 means no vignetting so do not circle crop\n",
    "    # create circle around center of image to get rid of vignette and other noise \n",
    "    img_size = np.shape(img)\n",
    "    center = (img_size[1]//2,img_size[0]//2)\n",
    "    use_thresh = GAUSS_THRESH\n",
    "    if radiusOption == 0:\n",
    "        # check to see if there is vignetting or if the picture is a dermoscopy image in which case it will be a circular image with the corners all black. \n",
    "        # In this case we need to removes the corners\n",
    "        find_black_circle = np.where(img[img_size[0]/2,:] > BLACK_THRESH)\n",
    "        c1 = np.min(find_black_circle)\n",
    "        c2 = np.max(find_black_circle)\n",
    "\n",
    "        if c1 > CIRCLE_THRESH:\n",
    "            radius = (c2 - c1)//2\n",
    "            use_thresh = .095\n",
    "        else:\n",
    "            radius = np.min(center)\n",
    "\n",
    "    else:\n",
    "        radius = np.max(center)*1.1\n",
    "\n",
    "    # create gaussian hump square matrix \n",
    "    gauss_hump = make2DGaussian(np.max(img_size),radius)\t\n",
    "    py1 = (gauss_hump.shape[0] - np.min(img_size))//2\n",
    "    py2 = py1 + np.min(img_size)\n",
    "    circle_mask = gauss_hump[py1:py2,:]\n",
    "\n",
    "    # apply a binary filter to the guassian hump at a certain level to take a cross section (which will be a circle to get the circle crop)\n",
    "    circle_mask[circle_mask < use_thresh] = 0\n",
    "    circle_mask[circle_mask >= use_thresh] = 1\n",
    "\n",
    "    # generate the image with the cropped section retaining original values and everything else being black\n",
    "    circle_crop = np.multiply(circle_mask[:,:,None], orig)\n",
    "    circle_crop[circle_crop == 0] = 255\n",
    "    circle_crop = np.array(circle_crop, 'uint8')\t# change matrix type to integers because pixel values are 8-bit integers from 0-255 not float\n",
    "\n",
    "    return circle_crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detectLesionUsingBlobs(gray_crop):\n",
    "    # BLOB DETECTION\n",
    "\n",
    "    Tracer()\n",
    "\n",
    "    # Blur image to remove noise\n",
    "    frame = cv2.GaussianBlur(gray_crop, (3, 3), 0)\n",
    "\n",
    "    # generate filter threshold thats custom to each picture\n",
    "    FILT_THRESH = np.max((150, np.max(gray_crop) + np.min(gray_crop) - np.mean(gray_crop))) + np.std(gray_crop)/4\t\t# divide by a randomly chosen factor\n",
    "\n",
    "    # define range of blob color in grayscale\n",
    "    blobMin = 0\n",
    "    blobMax = FILT_THRESH\n",
    "\n",
    "    # Sets pixels to white if in purple range, else will be set to black\n",
    "    mask = cv2.inRange(frame, blobMin, blobMax)\n",
    "\n",
    "    # Bitwise-AND of mask and purple only image - only used for display\n",
    "    res = cv2.bitwise_and(frame, frame, mask= mask)\n",
    "\n",
    "    #    mask = cv2.erode(mask, None, iterations=1)\n",
    "    # commented out erode call, detection more accurate without it\n",
    "\n",
    "    # dilate makes the in range areas larger\n",
    "    mask = cv2.dilate(mask, None, iterations=1)\n",
    "\n",
    "    # Set up the SimpleBlobdetector with default parameters.\n",
    "    params = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "    # Change thresholds\n",
    "    params.minThreshold = 0;\n",
    "    params.maxThreshold = 256;\n",
    "\n",
    "    # Filter by Area.\n",
    "    params.filterByArea = True\n",
    "    params.minArea = 1000\n",
    "\n",
    "    # Filter by Circularity\n",
    "    params.filterByCircularity = False\n",
    "    params.minCircularity = 0.1\n",
    "\n",
    "    # Filter by Convexity\n",
    "    params.filterByConvexity = False\n",
    "    params.minConvexity = 0.5\n",
    "\n",
    "    # Filter by Inertia. 0 is close to a line/stretched out ellipse and 1 is a circle\n",
    "    params.filterByInertia = False\n",
    "    params.minInertiaRatio = 0.5\n",
    "\n",
    "    detector = cv2.SimpleBlobDetector_create(params)\n",
    "\n",
    "    # Detect blobs.\n",
    "    reversemask=255-mask\n",
    "    keypoints = detector.detect(reversemask)\n",
    "\n",
    "    # Draw detected blobs as red circles.\n",
    "    # cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS ensures the size of the circle corresponds to the size of blob\n",
    "    im_with_keypoints = cv2.drawKeypoints(gray_crop, keypoints, np.array([]), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "    # Show keypoints\n",
    "    cv2.imshow(\"Keypoints\", im_with_keypoints)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getContours(thresh, orig):\n",
    "    (cnts, _) = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "\n",
    "    # calculate the area of each contour\n",
    "    area = np.zeros(len(cnts))\n",
    "    for i, contour in enumerate(cnts):\n",
    "        area[i] = cv2.contourArea(contour)\n",
    "        # print 'area: ', area[i]\n",
    "\n",
    "    # filter contours by area\n",
    "    cnts_filt_indx = [i for i,v in enumerate(area) if v > CONTOUR_AREA_THRESH]\n",
    "\n",
    "\n",
    "    # draw contours on original image\n",
    "    for cont_i in enumerate(cnts_filt_indx):\n",
    "        cnt = cnts[cont_i[1]]\n",
    "        cv2.drawContours(orig, [cnt], 0, (0,255,0), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def formatImageForNN(img, dim=(256,256)):\n",
    "    # Take input image (x,y,3) and make it a square image then resize the image to be 256x256 pixels for the neural network input\n",
    "    # (eventually make the function crop out a square of the convex hull of the mole)\n",
    "\n",
    "    # input image size\n",
    "    img_size = img.shape[0:2]\n",
    "\n",
    "    # make a new blank/black sqaure image with the larger of the two sides\n",
    "    sqr_side_lenth = np.max(img_size)\n",
    "    sqr_img = np.zeros((sqr_side_lenth,sqr_side_lenth,3),'uint8')\n",
    "\n",
    "    # fill in the top right corner of the new black image with the lesion image\n",
    "    sqr_img[0:img_size[0],0:img_size[1],:] = img \n",
    "\n",
    "    # resize the image to be a 256 x 256 \n",
    "    resized = cv2.resize(sqr_img,dim,interpolation = cv2.INTER_AREA)\n",
    "    # cv2.imshow('t',resized)\n",
    "\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preProcessImage(original, plotting = False):\n",
    "    # import plotting library\n",
    "    if plotting:\n",
    "        from matplotlib import pyplot as plt\n",
    "\n",
    "    # check if the picture is in landscape, if not make it landscape by rotating in 90 degrees\n",
    "    rows,cols,colors = original.shape\n",
    "    if rows > cols:\n",
    "        orig = np.zeros([cols,rows,colors])\n",
    "        for f in range(original.shape[2]):\n",
    "            orig[:,:,f] = np.fliplr(original[:,:,f].T)\t# rotate 90 degrees clockwise\n",
    "        orig = np.array(orig[1:-1,1:-1], 'uint8')\t# get rid of black border on most images and change to correct format type\n",
    "    else:\n",
    "        orig = original[1:-1,1:-1]\t# get rid of black border on most images\n",
    "\n",
    "    # convert to gray scale\n",
    "    gray_img = cv2.cvtColor(orig,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # check to see if corners of the image are dark which would indicate vignetting. If so, then apply the circle crop\n",
    "    box1 = 5\n",
    "    box2 = 10\n",
    "    if np.mean(gray_img[box1:box2,box1:box2]) < VIGNETTE_THRESH or np.mean(gray_img[-box2:-box1,-box2:-box1]) < VIGNETTE_THRESH:\n",
    "    # if gray_img[0,0] > VIGNETTE_THRESH or gray_img[-1,-1] > VIGNETTE_THRESH:\n",
    "        # crop circle using 2D guassian with mean zero variable variance (radius)\n",
    "        circle_crop = circleCrop(gray_img, orig, 0)\n",
    "    else:\n",
    "        circle_crop = circleCrop(gray_img, orig, 1)\n",
    "\n",
    "    # gray scale the new circle cropped image\n",
    "    gray_crop = cv2.cvtColor(circle_crop,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # # Blob detection method\n",
    "    # detectLesionUsingBlobs(gray_crop)\n",
    "\n",
    "\n",
    "    # # increase contrast locally\n",
    "    # clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    # contra1 = clahe.apply(gray_crop)\n",
    "    # # increase contrast globally\n",
    "    # glob_contra = cv2.equalizeHist(gray_crop)\n",
    "\n",
    "\n",
    "    # generate filter threshold thats custom to each picture\n",
    "    FILT_THRESH = np.max((150, np.max(gray_crop) + np.min(gray_crop) - np.mean(gray_crop))) + np.std(gray_crop)/10\t\t# divide by a randomly chosen factor\n",
    "\n",
    "    # apply binary filter to extract darker skin\n",
    "    thresh = cv2.threshold(gray_crop, FILT_THRESH, 255, 0)[1]\t\t# same thing as:\tfilt[filt>FILT_THRESH] = 255, filt[filt<=FILT_THRESH] = 0\n",
    "\n",
    "    # # find contours\n",
    "    # cnts, cnts_filt_indx = getContours(thresh, orig)\n",
    "\n",
    "    # apply binary filter to the original colored image\n",
    "    lesion = copy.deepcopy(circle_crop)\n",
    "    lesion[thresh == 255] = (0,0,0)\n",
    "    lesion = cv2.cvtColor(lesion, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # run the canny edge detector\n",
    "    lesion_gray = cv2.cvtColor(lesion, cv2.COLOR_RGB2GRAY)\n",
    "    lesion_edges = cv2.Canny(lesion_gray, 100,200)\n",
    "\n",
    "    # format image shape and size for the neural network\n",
    "    final_processed = formatImageForNN(lesion)\n",
    "\n",
    "\n",
    "    if plotting:\n",
    "        # plot some stuff\n",
    "        plt.subplot(171),plt.imshow(cv2.cvtColor(orig, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "        plt.subplot(172),plt.imshow(cv2.cvtColor(circle_crop, cv2.COLOR_BGR2RGB))\n",
    "        plt.title('Crop'), plt.xticks([]), plt.yticks([])\n",
    "        plt.subplot(173),plt.imshow(gray_crop)\n",
    "        plt.title('Contrast'), plt.xticks([]), plt.yticks([])\n",
    "        plt.subplot(174),plt.imshow(thresh)\n",
    "        plt.title('Filter'), plt.xticks([]), plt.yticks([])\n",
    "        plt.subplot(175), plt.imshow(lesion_edges)\n",
    "        plt.title('Edges'), plt.xticks([]), plt.yticks([])\n",
    "        plt.subplot(176),plt.imshow(lesion)\n",
    "        plt.title('Processed'), plt.xticks([]), plt.yticks([])\n",
    "        plt.subplot(177),plt.imshow(final_processed)\n",
    "        plt.title('Resized'), plt.xticks([]), plt.yticks([])\n",
    "        plt.show()\n",
    "\n",
    "        # plt.savefig('figures/segmentation_' + str(np.round(np.random.rand()*100)) + '.png', bbox_inches='tight')\n",
    "        # cv2.waitKey(0)\n",
    "\n",
    "    # ipdb.set_trace()\n",
    "\n",
    "    return final_processed, thresh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDataLabels(options):\n",
    "    # Data files\n",
    "    train_data_truth_filename = 'data/dataset_' + options.dataset + '/raw/ISIC_' + options.year + '_Training_GroundTruth.csv'\n",
    "    test_data_truth_filename = 'data/dataset_' + options.dataset + '/raw/ISIC_' + options.year + '_Test_GroundTruth.csv'\n",
    "\n",
    "    # import data from CSV (train)\n",
    "    open_train = open(train_data_truth_filename,'rb')\n",
    "    open_test = open(test_data_truth_filename,'rb')\n",
    "    train_data = np.asarray(list(csv.reader(open_train)))\n",
    "    test_data = np.asarray(list(csv.reader(open_test)))\n",
    "\n",
    "    # extract the image labels and convert benign and malignant strings to binary  {0,1}\n",
    "    img_names_train = copy.deepcopy(train_data[:,0])\n",
    "    y_train = copy.deepcopy(train_data[:,1])\n",
    "    y_train[y_train == 'benign'] = 0\n",
    "    y_train[y_train == 'malignant'] = 1\n",
    "    y_train[y_train == '0.0'] = 0\n",
    "    y_train[y_train == '1.0'] = 1\n",
    "    labels_train = np.array(y_train,'uint8')\n",
    "\n",
    "    img_names_test = copy.deepcopy(test_data[:,0])\n",
    "    y_test = copy.deepcopy(test_data[:,1])\n",
    "    y_test[y_test == '0.0'] = 0\n",
    "    y_test[y_test == '1.0'] = 1\n",
    "    y_test[y_test == 'benign'] = 0\n",
    "    y_test[y_test == 'malignant'] = 1\n",
    "    labels_test = np.array(y_test,'uint8')\n",
    "\n",
    "    # # save formatted labels\n",
    "    # np.savetxt(\"labels.csv\", y, delimiter=',')\n",
    "\n",
    "    labels = MATLABstruct()\n",
    "    img_names = MATLABstruct()\n",
    "\n",
    "    labels.train = labels_train\n",
    "    labels.test = labels_test\n",
    "    img_names.train = img_names_train\n",
    "    img_names.test = img_names_test\n",
    "\n",
    "    return img_names, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBalancedDataLabels(trainOrTest, options):\n",
    "    # define trainOrTest as 'test' or 'train'\n",
    "    all_img_names, all_labels = getDataLabels(options)\n",
    "    path = 'data/dataset_' + options.dataset + '/formatted/' + trainOrTest + '/processed/balanced/*.jpeg'\n",
    "\n",
    "    if trainOrTest == 'train':\n",
    "        labels = all_labels.train\n",
    "        names = all_img_names.train \n",
    "    elif trainOrTest == 'test':\n",
    "        labels = all_labels.test\n",
    "        names = all_img_names.test \n",
    "\n",
    "    balanced_labels = np.array([])\n",
    "    for j, img_name in enumerate(glob.glob(path)):\n",
    "        # img_names[i] = img\n",
    "        indx = [i for i in range(names.shape[0]) if names[i]==img_name[-17:-5]]\n",
    "        add_label = labels[indx]\n",
    "\n",
    "        if balanced_labels.shape[0] == 0:\n",
    "            balanced_labels = add_label\n",
    "        else:\n",
    "            balanced_labels = np.vstack((balanced_labels,add_label))\n",
    "\n",
    "    balanced_labels = balanced_labels.reshape(balanced_labels.shape[0],)\n",
    "    return balanced_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSegmentationError(seg_truth_file_path, seg_estimate, error_thresh=.2):\n",
    "    # calculate the area of the segmentation truth and estimate and if they're within a certain error threshold of each other \n",
    "    # consider the image properly segmented (return error=0) and if not (return error=1) \n",
    "\n",
    "    # import truth binary mask as gray scale and invert it (by subtracting it from 255) to match format of seg_estimate\n",
    "    seg_truth = 255 - cv2.imread(seg_truth_file_path,0)\t\n",
    "\n",
    "    # normalize both images\n",
    "    seg_truth = seg_truth/255\n",
    "    seg_estimate = seg_estimate/255\n",
    "\n",
    "    # calculate what 5% of the total number of pixels in the image is and use that number as the error threshold\n",
    "    pixel_thresh = np.prod(seg_truth.shape)*error_thresh\n",
    "\n",
    "    # calculate the number of white pixels in each image \n",
    "    seg_truth_area = int(np.sum(seg_truth))\n",
    "    seg_estimate_area = int(np.sum(seg_estimate))\n",
    "\n",
    "    # calculate the difference in area between ground truth and preprocessed estimate of segmentation\n",
    "    area_diff = np.absolute(seg_truth_area - seg_estimate_area)\n",
    "\n",
    "    # two methods for calculating error\n",
    "    error = 0 if area_diff < pixel_thresh else 1\n",
    "\n",
    "    return error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######################## MAIN #############################\n",
    "def processAll(options):\n",
    "\n",
    "    path = options.data_input_path\n",
    "    names,labels = getDataLabels(options)\n",
    "    if options.name == 'train':\n",
    "        names = names.train\n",
    "        labels = labels.train\n",
    "    elif options.name == 'test':\n",
    "        names = names.test\n",
    "        labels = labels.test\n",
    "\n",
    "\n",
    "    # import all images from the training/test set\n",
    "    dataset = []\n",
    "    img_names = dict()\n",
    "    seg_error = 0\n",
    "    for i, img in enumerate(glob.glob(options.data_input_path)):\n",
    "        orig = cv2.imread(img)\t# load image i\n",
    "        img_names[i] = img\n",
    "\n",
    "        if options.clean:\n",
    "            p1, seg_estimate = preProcessImage(orig, options.show_images)\t# show_images is a global variables\n",
    "\n",
    "            # calculate segmentation error\n",
    "            if options.calculate_error:\n",
    "                seg_truth_file_path = options.data_input_path[:-5] + img_names[i][-16:-4] + '_Segmentation.png'\n",
    "                seg_error += getSegmentationError(seg_truth_file_path, seg_estimate)\n",
    "\n",
    "            folder_processed_name = 'processed/'\n",
    "        else:\n",
    "            orig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)\n",
    "            p1 = formatImageForNN(orig)\n",
    "            folder_processed_name = 'unprocessed/'\n",
    "\n",
    "        # save image as jpeg in the folder corresponing to its label. This is for tensorflow-slim format purposes\n",
    "        if names[i]==img_names[i][-16:-4] and options.separate_imgs_by_label:\n",
    "            if labels[i] == 0: \n",
    "                folder_label_name = 'label_0/'\n",
    "            elif labels[i] == 1:\n",
    "                folder_label_name = 'label_1/'\n",
    "        else:\n",
    "            folder_label_name = ''\n",
    "\n",
    "        if options.save:\n",
    "            # save the image\n",
    "            im = Image.fromarray(p1)\n",
    "            im.save(options.save_path + options.name + '/' + folder_processed_name + folder_label_name + img_names[i][-16:-4] + \".jpeg\")\n",
    "\n",
    "    # lesion segmentation error\n",
    "    error = seg_error/float(len(img_names))\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/dataset_2/raw/ISIC_2017_Training_GroundTruth.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-2e64c2a42029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-2e64c2a42029>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# processAll(train_options)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mprocessAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-e876398ca60d>\u001b[0m in \u001b[0;36mprocessAll\u001b[0;34m(options)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_input_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetDataLabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-617e394d226f>\u001b[0m in \u001b[0;36mgetDataLabels\u001b[0;34m(options)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# import data from CSV (train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mopen_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_truth_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mopen_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_truth_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/dataset_2/raw/ISIC_2017_Training_GroundTruth.csv'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # define variable clean as (clean=True: processing/cleaning/resizing images) or (c;ean=False: just resizing images)\n",
    "    # separate_imgs_by_label (False: images are all put in one folder, True: images are put into 2 separate folders based on their associated label)\n",
    "    train_options = MATLABstruct()\n",
    "    train_options.name = 'train'\n",
    "    train_options.clean = True\n",
    "    train_options.separate_imgs_by_label = True \n",
    "    train_options.save = True\t\t\n",
    "    train_options.dataset = '2'\n",
    "    train_options.year = '2016' if train_options.dataset == '1' else '2017' if train_options.dataset == '2' else '' \n",
    "    train_options.data_input_path = 'data/dataset_' + train_options.dataset + '/raw/ISIC_' + train_options.year + '_Training_Data/*.jpg'\n",
    "    train_options.save_path = 'data/dataset_' + train_options.dataset + '/cnn_data/balanced/'\t\t# \"data/formatted/\"\n",
    "    # train_options.data_input_path = \"scraping/scraped_data/*.jpg\"\n",
    "    # train_options.save_path = 'scraping/formatted/'\n",
    "    train_options.show_images = False\n",
    "    train_options.calculate_error = False\n",
    "\n",
    "    test_options = MATLABstruct()\n",
    "    test_options.name = 'test'\n",
    "    test_options.clean = True\n",
    "    test_options.separate_imgs_by_label = True \t\t\n",
    "    test_options.save = False\n",
    "    test_options.dataset = train_options.dataset\n",
    "    test_options.year = train_options.year\n",
    "    test_options.data_input_path = 'data/dataset_' + test_options.dataset + '/raw/ISIC_' + test_options.year + '_Test_Data/*.jpg'\n",
    "    test_options.save_path = 'data/dataset_' + test_options.dataset + '/cnn_data/balanced/' \t\t#\"data/formatted/balanced/\"\n",
    "    test_options.show_images = False\n",
    "    test_options.calculate_error = False\n",
    "\n",
    "    # processAll(train_options)\n",
    "    processAll(test_options)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
